{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el entorno está correctamente instalado, las líneas de código anteriores deben importar los paquetes sin ningún error.\n",
    "\n",
    "Nota: para el resto de las preguntas y soluciones de código, puede ingresar más celdas si lo considera necesario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y estudio de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargue los datos desde el archivo *adult_data.csv*. Para esto puede utilizar la librería *pandas* con su función *read_csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('adult_data.csv',skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprima los nombres de las columnas (atributos), e investigue la documentación para entender que significa cada uno de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'age', u'workclass', u'fnlwgt', u'education', u'education-num',\n",
       "       u'marital-status', u'occupation', u'relationship', u'race', u'sex',\n",
       "       u'capital-gain', u'capital-loss', u'hours-per-week', u'native-country',\n",
       "       u'income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: A continuación realice algunas conjeturas de cuáles pueden llegar a ser los atributos de mayor utilidad para predecir el nivel de ingresos (income) de una persona.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA: Los atributos que creemos tienen más relevancia son: capital-gain, capital-loss, education y occupation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar la columna **income** en un array **y** que será utilizada como atributo clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = np.array(df.income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar la columna **fnlwgt** ya que no aporta a la solución del problema. También eliminar la columna **education-num** ya que duplica la información de la columna 'education'. Por último, eliminar la columna **income** ya que es la columna que contiene la clase que se pretende predecir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del df['fnlwgt']\n",
    "del df['education-num']\n",
    "del df['income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los atributos cuyos valores son categorías ('workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'), deben de transformarse a valores numéricos para poder ser utilizados como entradas en los modelos de scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Por qué no es apropiado transformar un atributo de categoría en simples índices numéricos?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA: Porque se generaría una relación de órden y magnitud que el algoritmo de aprendizaje puede tomar y no es real.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice las clases *LabelEncoder* y *OneHotEncoder* del paquete *preprocessing* de *sklearn* para transformar los atributos de categorías en atributos numéricos. Guarde los datos de entrada en una matriz **X**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2699: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing\n",
    "\n",
    "aTransformar = ['workclass', 'education', 'marital-status', 'sex','occupation', 'native-country', 'relationship', 'race']\n",
    "\n",
    "le = {}\n",
    "\n",
    "for t in aTransformar:\n",
    "    le[t] = sklearn.preprocessing.LabelEncoder()\n",
    "    le[t].fit(df[t])\n",
    "    df[t] = le[t].transform(df[t])\n",
    "    \n",
    "features = [df.columns.get_loc(f) for f in aTransformar]\n",
    "\n",
    "ohe = sklearn.preprocessing.OneHotEncoder(categorical_features=features, sparse=False)\n",
    "X = ohe.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          2.17400000e+03,   0.00000000e+00,   4.00000000e+01],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.30000000e+01],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.00000000e+01],\n",
       "       ..., \n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.00000000e+01],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   6.00000000e+01],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   5.50000000e+01]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Cuántos y cuáles son los nuevos atributos del dataset?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:** El "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['workclass/?', 'workclass/Federal-gov', 'workclass/Local-gov', 'workclass/Private', 'workclass/Self-emp-inc', 'workclass/Self-emp-not-inc', 'workclass/State-gov', 'workclass/Without-pay', 'education/10th', 'education/11th', 'education/12th', 'education/1st-4th', 'education/5th-6th', 'education/7th-8th', 'education/9th', 'education/Assoc-acdm', 'education/Assoc-voc', 'education/Bachelors', 'education/Doctorate', 'education/HS-grad', 'education/Masters', 'education/Preschool', 'education/Prof-school', 'education/Some-college', 'marital-status/Divorced', 'marital-status/Married-AF-spouse', 'marital-status/Married-civ-spouse', 'marital-status/Married-spouse-absent', 'marital-status/Never-married', 'marital-status/Separated', 'marital-status/Widowed', 'occupation/?', 'occupation/Adm-clerical', 'occupation/Armed-Forces', 'occupation/Craft-repair', 'occupation/Exec-managerial', 'occupation/Farming-fishing', 'occupation/Handlers-cleaners', 'occupation/Machine-op-inspct', 'occupation/Other-service', 'occupation/Priv-house-serv', 'occupation/Prof-specialty', 'occupation/Protective-serv', 'occupation/Sales', 'occupation/Tech-support', 'occupation/Transport-moving', 'relationship/Husband', 'relationship/Not-in-family', 'relationship/Other-relative', 'relationship/Own-child', 'relationship/Unmarried', 'relationship/Wife', 'race/Amer-Indian-Eskimo', 'race/Asian-Pac-Islander', 'race/Black', 'race/Other', 'race/White', 'sex/Female', 'sex/Male', 'native-country/?', 'native-country/Cambodia', 'native-country/Canada', 'native-country/China', 'native-country/Columbia', 'native-country/Cuba', 'native-country/Dominican-Republic', 'native-country/Ecuador', 'native-country/El-Salvador', 'native-country/England', 'native-country/France', 'native-country/Germany', 'native-country/Greece', 'native-country/Guatemala', 'native-country/Haiti', 'native-country/Honduras', 'native-country/Hong', 'native-country/India', 'native-country/Iran', 'native-country/Ireland', 'native-country/Italy', 'native-country/Jamaica', 'native-country/Japan', 'native-country/Laos', 'native-country/Mexico', 'native-country/Nicaragua', 'native-country/Outlying-US(Guam-USVI-etc)', 'native-country/Peru', 'native-country/Philippines', 'native-country/Poland', 'native-country/Portugal', 'native-country/Puerto-Rico', 'native-country/Scotland', 'native-country/South', 'native-country/Taiwan', 'native-country/Thailand', 'native-country/Trinadad&Tobago', 'native-country/United-States', 'native-country/Vietnam', 'native-country/Yugoslavia', 'age', 'capital-gain', 'capital-loss', 'hours-per-week']\n"
     ]
    }
   ],
   "source": [
    "def obtenerNombreFeature(i):\n",
    "    \n",
    "    if i >= ohe.feature_indices_[-1]:\n",
    "        \n",
    "        noCategoricalIndex = i - ohe.feature_indices_[-1]\n",
    "        \n",
    "        j = -1\n",
    "        n = -1\n",
    "        while j != noCategoricalIndex:\n",
    "            n += 1\n",
    "            if df.columns[n] not in aTransformar:\n",
    "                j += 1\n",
    "        return df.columns[n]\n",
    "\n",
    "    else:\n",
    "        enumerated_features = reversed([x for x in enumerate(ohe.feature_indices_)])\n",
    "        pos, categoria = next((pos, j) for (pos, j) in enumerated_features if j <= i)\n",
    "        nombreCategoria = df.columns[sorted(ohe.categorical_features)[pos]]\n",
    "        \n",
    "        etiqueta = i - categoria\n",
    "        nombreEtiqueta = le[nombreCategoria].classes_[etiqueta]\n",
    "        \n",
    "        return nombreCategoria + \"/\" + nombreEtiqueta\n",
    "\n",
    "print([obtenerNombreFeature(i) for i in range(len(X[0]))])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partición de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder entrenar y testear un algoritmo de aprendizaje, es necesario primero particionar los datos en dos conjuntos disjuntos de entrenamiento y testeo. Separe aleatoriamente un 25% de los datos para testeo, llame a los atributos de entrada como **X_test** y al vector de salida esperado **y_test**. El 75% restante se utilizará para el entrenamiento, nombre a la matriz con los datos de entrada como **X_train** y al vector de salida correspondiente como **y_train**.\n",
    "Para esto puede utilizar la función *train_test_split* del paquete *cross_validation* de *sklearn*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.cross_validation\n",
    "X_train,X_test,y_train,y_test = sklearn.cross_validation.train_test_split(X,y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine el tamaño de las matrices y vectores generados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3750"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3750"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos particionados los datos en entrenamiento y testeo, podemos comenzar a entrenar los algoritmos.\n",
    "\n",
    "Genere un modelo 'dt' entrenando un algoritmo de árboles de decisión (ver el paquete *tree* de *sklearn*) con el vector de entrada X_train y el vector de salida y_train. Utilice los valores por defecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.tree as tree\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genere un modelo 'nb' entrenando un algoritmo de Naive Bayes (ver el paquete *naive_bayes* de *sklearn*) con el vector de entrada X_train y el vector de salida y_train. Utilice los valores por defecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.naive_bayes as naive_bayes\n",
    "\n",
    "\n",
    "nb = naive_bayes.GaussianNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genere un modelo 'svc' entrenando un algoritmo de Support Vector Machines (ver el paquete *svm* de *sklearn*) con el vector de entrada X_train y el vector de salida y_train. Utilice los valores por defecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.svm as svm\n",
    "\n",
    "svc = svm.SVC()\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de tener los modelos entrenados, podemos medir qué tan bien funcionan los modelos (su capacidad de predicción) utlizando medidas standard como accuracy, precision, recall y medida-f."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: De la definición de cada una de las medidas de perfomance (accuracy, precision, recall y medida-f)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**\n",
    "Accuracy: Se define como el numero de predicciones correctas divididas entre el numero total de predicciones hechas y multiplicadas por 100 para convertirse en un porcentaje.\n",
    "\n",
    "Precision:Es el número de Verdaderos Positivos dividido entre la suma de los Verdaderos Positivos y los Falsos Positivos, dicho en otras palabras es el numero de predicciones positivas sobre el numero de valores de clase positivos predichos.\n",
    "\n",
    "Recall: Es el número de Verdaderos Positivos dividido entre la suma de los Verdaderos Positivos y los Falsos Negativos. Es el numero de predicciones positivas dividido entre el numero de valores positivos en los datos del test.\n",
    "\n",
    "Medida-f: Se calcula como 2*((precision*recall)/(precision+recall)) y representa el balance entre recall y la precisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemente una función 'imprimir_performance' que dado un vector de entrada 'X', un vector de salida 'y', y un clasificador 'clf':\n",
    "- Realice la predicción para el vector de entrada X.\n",
    "- Imprima la medida de accuracy.\n",
    "- Imprima precision, recall y medida f de cada clase.\n",
    "- Imprima la matriz de confusión.\n",
    "\n",
    "Para esto puede utilizar el paquete *metrics* de *sklearn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "\n",
    "def imprimir_performance(X, y, clf):\n",
    "    # predicciones = np.array([clf.predict(np.array(x).reshape(1,-1)) for x in X.values])\n",
    "    predicciones = clf.predict(np.array(X))\n",
    "        \n",
    "    print(\"Accuracy: \" + str(metrics.accuracy_score(y, predicciones)))\n",
    "    \n",
    "    for l in [' <=50K', ' >50K']:\n",
    "        print(\"Label \" + l)\n",
    "        print(\"   Precision: \" + str(metrics.precision_score(y, predicciones, pos_label=l)))\n",
    "        print(\"   Recall: \" + str(metrics.recall_score(y, predicciones, pos_label=l)))\n",
    "        print(\"   Medida-f: \" + str(metrics.f1_score(y, predicciones, pos_label=l)))\n",
    "        \n",
    "    print(\"Confussion matrix:\\n\" + str(metrics.confusion_matrix(y, predicciones)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice la función **imprimir_performance** para imprimir las medidas de performance para el clasificador **dt** basado en árboles de decisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7896\n",
      "Label  <=50K\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pos_label=' <=50K' is not a valid label: array(['<=50K', '>50K'], \n      dtype='|S5')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-ed140fc9f52b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimprimir_performance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-479e2c6927c1>\u001b[0m in \u001b[0;36mimprimir_performance\u001b[0;34m(X, y, clf)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m' <=50K'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' >50K'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Label \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"   Precision: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicciones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"   Recall: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicciones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"   Medida-f: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicciones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Nicolas\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1201\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1204\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Nicolas\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m    982\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m                     raise ValueError(\"pos_label=%r is not a valid label: %r\" %\n\u001b[0;32m--> 984\u001b[0;31m                                      (pos_label, present_labels))\n\u001b[0m\u001b[1;32m    985\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: pos_label=' <=50K' is not a valid label: array(['<=50K', '>50K'], \n      dtype='|S5')"
     ]
    }
   ],
   "source": [
    "imprimir_performance(X_test, y_test, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice la función **imprimir_performance** para imprimir las medidas de performance para el clasificador **nb** basado en Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7856\n",
      "Label  <=50K\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pos_label=' <=50K' is not a valid label: array(['<=50K', '>50K'], \n      dtype='|S5')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-5c900cded5cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimprimir_performance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-479e2c6927c1>\u001b[0m in \u001b[0;36mimprimir_performance\u001b[0;34m(X, y, clf)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m' <=50K'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' >50K'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Label \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"   Precision: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicciones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"   Recall: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicciones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"   Medida-f: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicciones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Nicolas\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1201\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1204\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Nicolas\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m    982\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m                     raise ValueError(\"pos_label=%r is not a valid label: %r\" %\n\u001b[0;32m--> 984\u001b[0;31m                                      (pos_label, present_labels))\n\u001b[0m\u001b[1;32m    985\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: pos_label=' <=50K' is not a valid label: array(['<=50K', '>50K'], \n      dtype='|S5')"
     ]
    }
   ],
   "source": [
    "imprimir_performance(X_test, y_test, nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice la función **imprimir_performance** para imprimir las medidas de performance para el clasificador **svc** basado en Support Vector Machines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imprimir_performance(X_test, y_test, svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Realice un breve análisis de los resultados obtenidos.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrene y mida la perfomance de los calsifificadores anteriores, pero ahora utilizando el algoritmo de validación cruzada (cross validation) tomando 5 particiones. Imprima el promedio de accuracy obtenido para cada modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection as ms\n",
    "\n",
    "cross = ms.KFold(n_splits=5)\n",
    "\n",
    "clfs = [(\"DT\", tree.DecisionTreeClassifier()), (\"NB\", naive_bayes.GaussianNB()), (\"SVC\",  svm.SVC())]\n",
    "\n",
    "performances = {}\n",
    "\n",
    "for nombre, clf in clfs:\n",
    "    \n",
    "    sumAcc = 0\n",
    "    \n",
    "    for train, test in cross.split(X_train, y_train):\n",
    "           \n",
    "        clf.fit(X_train[train],y_train[train])\n",
    "        predicciones = clf.predict(X_train[test])\n",
    "        sumAcc += metrics.accuracy_score(y_train[test], predicciones)\n",
    "    \n",
    "    performances[nombre] = sumAcc/5\n",
    "    \n",
    "    print(\"Accuracy \" + nombre + \": \" + str(sumAcc/5))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Describa brevemente cuáles son las ventajas de utilizar validación cruzada en vez de realizar una único esquema de partición como se hizo al principio.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA: La ventaja principal de utilizar el método de validación cruzada es que todos los ejemplos presentes en la muestra son usados para la etapa de testeo y la mayoría de estos para la etapa de entrenamiento del modelo.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejorando los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen varias técnicas que pueden ser utilizadas para mejorar los resultados de nuestros modelos. A continuación utilizaremos técnias de **selección de atributos** y de **ajuste de hiperparámetros**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestros entrenamientos hemos utilizado todos los atributos disponibles para entrenar nuestros modelos. Pero no siempre esto lleva a los mejores resultados, de hecho muchas veces, trabajar con un conjunto reducido de atributos devuelve mejores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Investigue de qué se trata la técnica de selección de atributos (feature selection) y argumente brevemente por qué puede mejorar la performance de un algoritmo de aprendizaje automático.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA: La técnica de selección de atributos consiste en la disminución del espacio total de atributos, quitando los irrelevantes o redundantes. Es decir escoger un subconjunto de atributos mínimo tal que no decrezca significativamente la tasa de aciertos. Esto mejoraría la eficiencia de los algoritmos ya que al contener menos datos las iteraciones se realizarian mas deprisa y los resultados serían visibles en menos tiempo.  **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando el paquete *feature_selection* de *sklearn*, seleccione e imprima la lista de los 20 mejores atributos según la medida estadística chi^2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.feature_selection as fs\n",
    "\n",
    "selector = fs.SelectKBest(fs.chi2,k=20)\n",
    "selector.fit_transform(X_train, y_train).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intente obtener la lista de los mejores N atributos, donde N sea la cantidad mínima posible de atributos que mantenga o mejore las medidas de performance obtenidas con validación cruzada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def realizarCV(clf, X, y):\n",
    "    \n",
    "    cross = ms.KFold(n_splits=5)\n",
    "    sumAcc = 0\n",
    "    \n",
    "    for train, test in cross.split(X, y):\n",
    "        \n",
    "        clf.fit(X[train],y[train])\n",
    "        predicciones = clf.predict(np.array(X[test]))\n",
    "        sumAcc += metrics.accuracy_score(y[test], predicciones)\n",
    "    \n",
    "    return sumAcc / 5\n",
    "\n",
    "plt.clf()\n",
    "selectores = {}\n",
    "\n",
    "for nombre, clf in clfs:\n",
    "\n",
    "    performanceTarget = realizarCV(clf, X_train, y_train)\n",
    "    nuevasPerformances = []\n",
    "    mejoresAtributos = []\n",
    "    \n",
    "    for n in xrange(1,20):\n",
    "        kSelector = fs.SelectKBest(fs.chi2,k=n)\n",
    "        X_filtered = kSelector.fit_transform(X_train, y_train).astype(np.int32)\n",
    "        res = realizarCV(clf, X_filtered, y_train)\n",
    "        \n",
    "        if len(mejoresAtributos) == 0 and res > performances[nombre]:\n",
    "            mejoresAtributos = kSelector.get_support()\n",
    "            selectores[nombre] = kSelector\n",
    "\n",
    "        nuevasPerformances.append(res)\n",
    "    \n",
    "    print(nombre)\n",
    "    print(mejoresAtributos)\n",
    "    plt.plot(nuevasPerformances, label=nombre)\n",
    "    \n",
    "    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el conjunto de atributos obtenido, entrene los clasificadores nuevamente y verifique que las medidas de precision, recall mejoran en general:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for nombre, clf in clfs:\n",
    "    X_selected = selectores[nombre].transform(X_train)\n",
    "    X_test_selected = selectores[nombre].transform(X_test)\n",
    "    clf.fit(X_selected,y_train)\n",
    "    imprimir_performance(X_test_selected, y_test,clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo general, cada algoritmo y modelo de aprendizaje automático posee parámetros configurables. Estos parámetros se los suele denominar 'hiperparámetros' del algoritmo, ya que son parámetros que el algoritmo no ajusta automáticamente, sino que son ajustados por el \"usuario\".\n",
    "\n",
    "La correcta selección de estos hiperparámetros por lo general tiene una gran incidencia en la performance de los algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Para los modelos generados anteriormente (Árbol de decisión, Naive Bayes y Support Vector Machines), investigue en la documentación de scikit-learn cuáles son sus hiperparámetros y qué valores toman. A continuación liste y de una breve descripción de cada uno:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebe diferentes configuraciones de hiperparámetros para los modelos anteriores de modo de mejorar los resultados de performance obtenidos mediante la función *imprimir_performance*.\n",
    "\n",
    "Para esto puede realizarlo manualmente o buscar una estrategia más avanzada utilizando la clase *GridSearchCV* del paquete *grid_search* de *sklearn*. Esta clase permite definir una grilla de parámetros y posibles valores para luego entrenar el modelo con todas sus posibles combinaciones y devolver la configuración que retorna la mejor performance.\n",
    "\n",
    "En caso de tener que combinar varios procesos de extracción y selección de atributos junto con un modelo de aprendizaje, se recomienda utilizar la clase *Pipeline* del paquete *pipeline* de *sklearn*.\n",
    "\n",
    "Tener en cuenta que si la grilla es muy grande, el proceso puede requerir mucho tiempo de cómputo y memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sklearn.grid_search as gs\n",
    "\n",
    "params = {}\n",
    "params[\"SVC\"] = { \n",
    "    'C': [0.5,1,1.5],\n",
    "    'kernel': ['linear', 'poly', 'rbf'],\n",
    "}\n",
    "\n",
    "params[\"DT\"] = {\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'splitter' : ['best', 'random'],\n",
    "    'max_features' : ['auto', 'log2', None],\n",
    "    'min_samples_split' : [1,2,3,0.1,0.2],\n",
    "    'min_samples_leaf' : [1,2,3,0.2,0.4],\n",
    "    'min_impurity_split' : [1e-7,1e-8],\n",
    "    'min_weight_fraction_leaf' : [0,0.1,0.2]\n",
    "}\n",
    "params[\"NB\"] = {\n",
    "    \n",
    "}\n",
    "\n",
    "def obtenerScorer(fn):\n",
    "    return lambda estimator, X, y : fn(y, estimator.predict(np.array(X)))\n",
    "\n",
    "def obtenerMejorEstimador(params, scorer):\n",
    "\n",
    "    for nombre, clf in clfs:\n",
    "\n",
    "        print(\"==> \" + nombre)\n",
    "        gridSearch = gs.GridSearchCV(clf, params[nombre], scoring=scorer)\n",
    "        gridSearch.fit(X_train, y_train)\n",
    "        pad = \" \" * len(\"==>  \")\n",
    "        print(pad + str(gridSearch.best_score_))\n",
    "        print(pad + \"Best params: \" + str(gridSearch.best_params_))\n",
    "\n",
    "print(\"Accuracy\")\n",
    "obtenerMejorEstimador(params, obtenerScorer(metrics.accuracy_score))\n",
    "print(\"Precision\")\n",
    "obtenerMejorEstimador(params, obtenerScorer(lambda y, p: metrics.precision_score(y, p, pos_label=' <=50K')))\n",
    "print(\"Recall\")\n",
    "obtenerMejorEstimador(params, obtenerScorer(lambda y, p: metrics.recall_score(y, p, pos_label=' <=50K')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTAS:**\n",
    "- **Cuáles son los valores de los hiperparámetros con los cuales se obtienen los mejores resultados de performance?**\n",
    "- **Con qué modelo se obtienen los mejores resultados de precision y recall?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Escriba las conclusiones generales que haya obtenido de la tarea.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de Imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección trabajaremos con clasificación de imágenes. Cada instancia a clasificar es una imagen con un dígito escrito a mano. El objetivo es detectar el dígito correspondiente a cada imagen. Para eso utilizaremos un dataset de *sklearn.datasets* que contiene imágenes de dígitos escritos a mano etiquetadas. Cada imagen se representa como un vector de pixeles.\n",
    "\n",
    "Utilizar la función *load_digits* para importar los datos de dígitos escritos a mano. Inspeccionar su contenido (data, target, images y target_names), renderizar el dígito de la primera instancia del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.datasets as datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particionar los datos en dos conjuntos dijuntos de entrenamiento y testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xDigitsTrain,xDigitsTest,yDigitsTrain,yDigitsTest = sklearn.cross_validation.train_test_split(digits.data,digits.target,\n",
    "                                                                                              test_size =0.5)\n",
    "len(digits.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraer atributos de las imágenes para ser utilizados en el modelo de clasificación. Para esto, investigar las clases de Principal Component Analysis (PCA) del paquete sklearn.decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.decomposition\n",
    "\n",
    "pca = sklearn.decomposition.PCA(n_components=16)\n",
    "xDigitsTrain = pca.fit_transform(xDigitsTrain,yDigitsTrain)\n",
    "xDigitsTest = pca.transform(xDigitsTest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Explique el método de extracción de atributos y justifique su elección.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elija dos algoritmos de aprendizaje y entrene e intente obtener los mejores modelos de clasificación posibles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm as svm\n",
    "from sklearn import neural_network\n",
    "\n",
    "\n",
    "svc = svm.SVC(gamma=0.001)\n",
    "svc.fit(xDigitsTrain, yDigitsTrain)\n",
    "predictSvc = svc.predict(xDigitsTest)\n",
    "\n",
    "nn = sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(20,20), max_iter=80000,alpha=0.001)\n",
    "nn.fit(xDigitsTrain,yDigitsTrain)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprima los mejores resultados de precision, recall y accuracy para los algoritmos seleccionados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def imprimir_performance(X, y, clf):\n",
    "    # predicciones = np.array([clf.predict(np.array(x).reshape(1,-1)) for x in X.values])\n",
    "    predicciones = clf.predict(X)\n",
    "        \n",
    "    print(\"Accuracy: \" + str(metrics.accuracy_score(y, predicciones)))\n",
    "    \n",
    "\n",
    "    for l in range(10):\n",
    "        print(\"Label \" + str(l))\n",
    "        print(\"   Precision: \" + str(metrics.precision_score(y, predicciones, average = 'micro', labels=[l])))\n",
    "        print(\"   Recall: \" + str(metrics.recall_score(y, predicciones, average = 'micro', labels=[l])))\n",
    "        print(\"   Medida-f: \" + str(metrics.f1_score(y, predicciones, average = 'micro', labels=[l])))\n",
    "        \n",
    "    print(\"Confussion matrix:\\n\" + str(metrics.confusion_matrix(y, predicciones, )))\n",
    "    \n",
    "    \n",
    "imprimir_performance(xDigitsTest,yDigitsTest,svc)\n",
    "imprimir_performance(xDigitsTest,yDigitsTest,nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Analice los resultados obtenidos.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
