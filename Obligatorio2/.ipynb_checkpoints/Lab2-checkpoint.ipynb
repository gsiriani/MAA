{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el entorno está correctamente instalado, las líneas de código anteriores deben importar los paquetes sin ningún error.\n",
    "\n",
    "Nota: para el resto de las preguntas y soluciones de código, puede ingresar más celdas si lo considera necesario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y estudio de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargue los datos desde el archivo *adult_data.csv*. Para esto puede utilizar la librería *pandas* con su función *read_csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('adult_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprima los nombres de las columnas (atributos), e investigue la documentación para entender que significa cada uno de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'age', u'workclass', u'fnlwgt', u'education', u'education-num',\n",
       "       u'marital-status', u'occupation', u'relationship', u'race', u'sex',\n",
       "       u'capital-gain', u'capital-loss', u'hours-per-week', u'native-country',\n",
       "       u'income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: A continuación realice algunas conjeturas de cuáles pueden llegar a ser los atributos de mayor utilidad para predecir el nivel de ingresos (income) de una persona.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "capital-gain\n",
    "capital-loss\n",
    "education\n",
    "occupation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar la columna **income** en un array **y** que será utilizada como atributo clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = np.array(df.income)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar la columna **fnlwgt** ya que no aporta a la solución del problema. También eliminar la columna **education-num** ya que duplica la información de la columna 'education'. Por último, eliminar la columna **income** ya que es la columna que contiene la clase que se pretende predecir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del df['fnlwgt']\n",
    "del df['education-num']\n",
    "del df['income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los atributos cuyos valores son categorías ('workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'), deben de transformarse a valores numéricos para poder ser utilizados como entradas en los modelos de scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Por qué no es apropiado transformar un atributo de categoría en simples índices numéricos?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA: Porque se generaría una relación de órden y magnitud que el algoritmo de aprendizaje puede tomar y no es real...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice las clases *LabelEncoder* y *OneHotEncoder* del paquete *preprocessing* de *sklearn* para transformar los atributos de categorías en atributos numéricos. Guarde los datos de entrada en una matriz **X**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "\n",
    "aTransformar = ['workclass', 'education', 'marital-status', 'sex','occupation', 'native-country', 'relationship', 'race']\n",
    "\n",
    "le = {}\n",
    "\n",
    "for t in aTransformar:\n",
    "    le[t] = sklearn.preprocessing.LabelEncoder()\n",
    "    le[t].fit(df[t])\n",
    "    df[t] = le[t].transform(df[t])\n",
    "    \n",
    "features = [df.columns.get_loc(f) for f in aTransformar]\n",
    "\n",
    "ohe = sklearn.preprocessing.OneHotEncoder(categorical_features=features, sparse=False)\n",
    "X = ohe.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          2.17400000e+03,   0.00000000e+00,   4.00000000e+01],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.30000000e+01],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.00000000e+01],\n",
       "       ..., \n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   4.00000000e+01],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   6.00000000e+01],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00, ...,\n",
       "          0.00000000e+00,   0.00000000e+00,   5.50000000e+01]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Cuántos y cuáles son los nuevos atributos del dataset?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'age', u'workclass', u'education', u'marital-status', u'occupation',\n",
      "       u'relationship', u'race', u'sex', u'capital-gain', u'capital-loss',\n",
      "       u'hours-per-week', u'native-country'],\n",
      "      dtype='object')\n",
      "0 workclass/ ?\n",
      "1 workclass/ Federal-gov\n",
      "2 workclass/ Local-gov\n",
      "3 workclass/ Private\n",
      "4 workclass/ Self-emp-inc\n",
      "5 workclass/ Self-emp-not-inc\n",
      "6 workclass/ State-gov\n",
      "7 workclass/ Without-pay\n",
      "8 education/ 10th\n",
      "9 education/ 11th\n",
      "10 education/ 12th\n",
      "11 education/ 1st-4th\n",
      "12 education/ 5th-6th\n",
      "13 education/ 7th-8th\n",
      "14 education/ 9th\n",
      "15 education/ Assoc-acdm\n",
      "16 education/ Assoc-voc\n",
      "17 education/ Bachelors\n",
      "18 education/ Doctorate\n",
      "19 education/ HS-grad\n",
      "20 education/ Masters\n",
      "21 education/ Preschool\n",
      "22 education/ Prof-school\n",
      "23 education/ Some-college\n",
      "24 marital-status/ Divorced\n",
      "25 marital-status/ Married-AF-spouse\n",
      "26 marital-status/ Married-civ-spouse\n",
      "27 marital-status/ Married-spouse-absent\n",
      "28 marital-status/ Never-married\n",
      "29 marital-status/ Separated\n",
      "30 marital-status/ Widowed\n",
      "31 occupation/ ?\n",
      "32 occupation/ Adm-clerical\n",
      "33 occupation/ Armed-Forces\n",
      "34 occupation/ Craft-repair\n",
      "35 occupation/ Exec-managerial\n",
      "36 occupation/ Farming-fishing\n",
      "37 occupation/ Handlers-cleaners\n",
      "38 occupation/ Machine-op-inspct\n",
      "39 occupation/ Other-service\n",
      "40 occupation/ Priv-house-serv\n",
      "41 occupation/ Prof-specialty\n",
      "42 occupation/ Protective-serv\n",
      "43 occupation/ Sales\n",
      "44 occupation/ Tech-support\n",
      "45 occupation/ Transport-moving\n",
      "46 relationship/ Husband\n",
      "47 relationship/ Not-in-family\n",
      "48 relationship/ Other-relative\n",
      "49 relationship/ Own-child\n",
      "50 relationship/ Unmarried\n",
      "51 relationship/ Wife\n",
      "52 race/ Amer-Indian-Eskimo\n",
      "53 race/ Asian-Pac-Islander\n",
      "54 race/ Black\n",
      "55 race/ Other\n",
      "56 race/ White\n",
      "57 sex/ Female\n",
      "58 sex/ Male\n",
      "59 native-country/ ?\n",
      "60 native-country/ Cambodia\n",
      "61 native-country/ Canada\n",
      "62 native-country/ China\n",
      "63 native-country/ Columbia\n",
      "64 native-country/ Cuba\n",
      "65 native-country/ Dominican-Republic\n",
      "66 native-country/ Ecuador\n",
      "67 native-country/ El-Salvador\n",
      "68 native-country/ England\n",
      "69 native-country/ France\n",
      "70 native-country/ Germany\n",
      "71 native-country/ Greece\n",
      "72 native-country/ Guatemala\n",
      "73 native-country/ Haiti\n",
      "74 native-country/ Honduras\n",
      "75 native-country/ Hong\n",
      "76 native-country/ India\n",
      "77 native-country/ Iran\n",
      "78 native-country/ Ireland\n",
      "79 native-country/ Italy\n",
      "80 native-country/ Jamaica\n",
      "81 native-country/ Japan\n",
      "82 native-country/ Laos\n",
      "83 native-country/ Mexico\n",
      "84 native-country/ Nicaragua\n",
      "85 native-country/ Outlying-US(Guam-USVI-etc)\n",
      "86 native-country/ Peru\n",
      "87 native-country/ Philippines\n",
      "88 native-country/ Poland\n",
      "89 native-country/ Portugal\n",
      "90 native-country/ Puerto-Rico\n",
      "91 native-country/ Scotland\n",
      "92 native-country/ South\n",
      "93 native-country/ Taiwan\n",
      "94 native-country/ Thailand\n",
      "95 native-country/ Trinadad&Tobago\n",
      "96 native-country/ United-States\n",
      "97 native-country/ Vietnam\n",
      "98 native-country/ Yugoslavia\n",
      "0\n",
      "99 workclass\n",
      "1\n",
      "100 capital-loss\n",
      "2\n",
      "101 hours-per-week\n",
      "3\n",
      "102 native-country\n"
     ]
    }
   ],
   "source": [
    "def obtenerNombreFeature(i):\n",
    "    \n",
    "    if i >= ohe.feature_indices_[-1]:\n",
    "        \n",
    "        noCategoricalIndex = i - ohe.feature_indices_[-1]\n",
    "        \n",
    "        j = -1\n",
    "        n = 0\n",
    "        while j != noCategoricalIndex:\n",
    "            if df.columns[n] not in aTransformar:\n",
    "                j += 1\n",
    "            n += 1\n",
    "        return df.columns[n]\n",
    "\n",
    "    else:\n",
    "        enumerated_features = reversed([x for x in enumerate(ohe.feature_indices_)])\n",
    "        pos, categoria = next((pos, j) for (pos, j) in enumerated_features if j <= i)\n",
    "        nombreCategoria = df.columns[sorted(ohe.categorical_features)[pos]]\n",
    "        \n",
    "        etiqueta = i - categoria\n",
    "        nombreEtiqueta = le[nombreCategoria].classes_[etiqueta]\n",
    "        \n",
    "        return nombreCategoria + \"/\" + nombreEtiqueta\n",
    "\n",
    "print df.columns\n",
    "for i in range(len(X[0])):\n",
    "    print(str(i) + \" \" + obtenerNombreFeature(i))\n",
    "    \n",
    "#print([obtenerNombreFeature(i) for i in range(len(X[0]))])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partición de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder entrenar y testear un algoritmo de aprendizaje, es necesario primero particionar los datos en dos conjuntos disjuntos de entrenamiento y testeo. Separe aleatoriamente un 25% de los datos para testeo, llame a los atributos de entrada como **X_test** y al vector de salida esperado **y_test**. El 75% restante se utilizará para el entrenamiento, nombre a la matriz con los datos de entrada como **X_train** y al vector de salida correspondiente como **y_train**.\n",
    "Para esto puede utilizar la función *train_test_split* del paquete *cross_validation* de *sklearn*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.cross_validation\n",
    "X_train,X_test,y_train,y_test = sklearn.cross_validation.train_test_split(X,y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine el tamaño de las matrices y vectores generados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos particionados los datos en entrenamiento y testeo, podemos comenzar a entrenar los algoritmos.\n",
    "\n",
    "Genere un modelo 'dt' entrenando un algoritmo de árboles de decisión (ver el paquete *tree* de *sklearn*) con el vector de entrada X_train y el vector de salida y_train. Utilice los valores por defecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.tree as tree\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genere un modelo 'nb' entrenando un algoritmo de Naive Bayes (ver el paquete *naive_bayes* de *sklearn*) con el vector de entrada X_train y el vector de salida y_train. Utilice los valores por defecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.naive_bayes as naive_bayes\n",
    "\n",
    "\n",
    "nb = naive_bayes.GaussianNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genere un modelo 'svc' entrenando un algoritmo de Support Vector Machines (ver el paquete *svm* de *sklearn*) con el vector de entrada X_train y el vector de salida y_train. Utilice los valores por defecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn.svm as svm\n",
    "\n",
    "svc = svm.SVC()\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de tener los modelos entrenados, podemos medir qué tan bien funcionan los modelos (su capacidad de predicción) utlizando medidas standard como accuracy, precision, recall y medida-f."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: De la definición de cada una de las medidas de perfomance (accuracy, precision, recall y medida-f)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemente una función 'imprimir_performance' que dado un vector de entrada 'X', un vector de salida 'y', y un clasificador 'clf':\n",
    "- Realice la predicción para el vector de entrada X.\n",
    "- Imprima la medida de accuracy.\n",
    "- Imprima precision, recall y medida f de cada clase.\n",
    "- Imprima la matriz de confusión.\n",
    "\n",
    "Para esto puede utilizar el paquete *metrics* de *sklearn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "\n",
    "def imprimir_performance(X, y, clf):\n",
    "    # predicciones = np.array([clf.predict(np.array(x).reshape(1,-1)) for x in X.values])\n",
    "    predicciones = clf.predict(np.array(X))\n",
    "        \n",
    "    print(\"Accuracy: \" + str(metrics.accuracy_score(y, predicciones)))\n",
    "    \n",
    "    for l in [' <=50K', ' >50K']:\n",
    "        print(\"Label \" + l)\n",
    "        print(\"   Precision: \" + str(metrics.precision_score(y, predicciones, pos_label=l)))\n",
    "        print(\"   Recall: \" + str(metrics.recall_score(y, predicciones, pos_label=l)))\n",
    "        print(\"   Medida-f: \" + str(metrics.f1_score(y, predicciones, pos_label=l)))\n",
    "        \n",
    "    print(\"Confussion matrix:\\n\" + str(metrics.confusion_matrix(y, predicciones)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice la función **imprimir_performance** para imprimir las medidas de performance para el clasificador **dt** basado en árboles de decisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imprimir_performance(X_test, y_test, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice la función **imprimir_performance** para imprimir las medidas de performance para el clasificador **nb** basado en Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imprimir_performance(X_test, y_test, nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice la función **imprimir_performance** para imprimir las medidas de performance para el clasificador **svc** basado en Support Vector Machines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imprimir_performance(X_test, y_test, svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Realice un breve análisis de los resultados obtenidos.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrene y mida la perfomance de los calsifificadores anteriores, pero ahora utilizando el algoritmo de validación cruzada (cross validation) tomando 5 particiones. Imprima el promedio de accuracy obtenido para cada modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.model_selection as ms\n",
    "\n",
    "cross = ms.KFold(n_splits=5)\n",
    "\n",
    "clfs = [(\"DT\", tree.DecisionTreeClassifier()), (\"NB\", naive_bayes.GaussianNB()), (\"SVC\",  svm.SVC())]\n",
    "\n",
    "performances = {}\n",
    "\n",
    "for nombre, clf in clfs:\n",
    "    \n",
    "    sumAcc = 0\n",
    "    \n",
    "    for train, test in cross.split(X_train, y_train):\n",
    "           \n",
    "        clf.fit(X_train[train],y_train[train])\n",
    "        predicciones = clf.predict(X_train[test])\n",
    "        sumAcc += metrics.accuracy_score(y_train[test], predicciones)\n",
    "    \n",
    "    performances[nombre] = sumAcc/5\n",
    "    \n",
    "    print(\"Accuracy \" + nombre + \": \" + str(sumAcc/5))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Describa brevemente cuáles son las ventajas de utilizar validación cruzada en vez de realizar una único esquema de partición como se hizo al principio.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejorando los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen varias técnicas que pueden ser utilizadas para mejorar los resultados de nuestros modelos. A continuación utilizaremos técnias de **selección de atributos** y de **ajuste de hiperparámetros**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestros entrenamientos hemos utilizado todos los atributos disponibles para entrenar nuestros modelos. Pero no siempre esto lleva a los mejores resultados, de hecho muchas veces, trabajar con un conjunto reducido de atributos devuelve mejores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Investigue de qué se trata la técnica de selección de atributos (feature selection) y argumente brevemente por qué puede mejorar la performance de un algoritmo de aprendizaje automático.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando el paquete *feature_selection* de *sklearn*, seleccione e imprima la lista de los 20 mejores atributos según la medida estadística chi^2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.feature_selection as fs\n",
    "\n",
    "selector = fs.SelectKBest(fs.chi2,k=20)\n",
    "selector.fit_transform(X_train, y_train).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intente obtener la lista de los mejores N atributos, donde N sea la cantidad mínima posible de atributos que mantenga o mejore las medidas de performance obtenidas con validación cruzada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def realizarCV(clf, X, y):\n",
    "    \n",
    "    cross = ms.KFold(n_splits=5)\n",
    "    sumAcc = 0\n",
    "    \n",
    "    for train, test in cross.split(X, y):\n",
    "        \n",
    "        clf.fit(X[train],y[train])\n",
    "        predicciones = clf.predict(np.array(X[test]))\n",
    "        sumAcc += metrics.accuracy_score(y[test], predicciones)\n",
    "    \n",
    "    return sumAcc / 5\n",
    "\n",
    "plt.clf()\n",
    "selectores = {}\n",
    "\n",
    "for nombre, clf in clfs:\n",
    "\n",
    "    performanceTarget = realizarCV(clf, X_train, y_train)\n",
    "    nuevasPerformances = []\n",
    "    mejoresAtributos = []\n",
    "    \n",
    "    for n in xrange(1,20):\n",
    "        kSelector = fs.SelectKBest(fs.chi2,k=n)\n",
    "        X_filtered = kSelector.fit_transform(X_train, y_train).astype(np.int32)\n",
    "        res = realizarCV(clf, X_filtered, y_train)\n",
    "        \n",
    "        if len(mejoresAtributos) == 0 and res > performances[nombre]:\n",
    "            mejoresAtributos = kSelector.get_support()\n",
    "            selectores[nombre] = kSelector\n",
    "\n",
    "        nuevasPerformances.append(res)\n",
    "    \n",
    "    print(nombre)\n",
    "    print(mejoresAtributos)\n",
    "    plt.plot(nuevasPerformances, label=nombre)\n",
    "    \n",
    "    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el conjunto de atributos obtenido, entrene los clasificadores nuevamente y verifique que las medidas de precision, recall mejoran en general:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for nombre, clf in clfs:\n",
    "    X_selected = selectores[nombre].transform(X_train)\n",
    "    X_test_selected = selectores[nombre].transform(X_test)\n",
    "    clf.fit(X_selected,y_train)\n",
    "    imprimir_performance(X_test_selected, y_test,clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo general, cada algoritmo y modelo de aprendizaje automático posee parámetros configurables. Estos parámetros se los suele denominar 'hiperparámetros' del algoritmo, ya que son parámetros que el algoritmo no ajusta automáticamente, sino que son ajustados por el \"usuario\".\n",
    "\n",
    "La correcta selección de estos hiperparámetros por lo general tiene una gran incidencia en la performance de los algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Para los modelos generados anteriormente (Árbol de decisión, Naive Bayes y Support Vector Machines), investigue en la documentación de scikit-learn cuáles son sus hiperparámetros y qué valores toman. A continuación liste y de una breve descripción de cada uno:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebe diferentes configuraciones de hiperparámetros para los modelos anteriores de modo de mejorar los resultados de performance obtenidos mediante la función *imprimir_performance*.\n",
    "\n",
    "Para esto puede realizarlo manualmente o buscar una estrategia más avanzada utilizando la clase *GridSearchCV* del paquete *grid_search* de *sklearn*. Esta clase permite definir una grilla de parámetros y posibles valores para luego entrenar el modelo con todas sus posibles combinaciones y devolver la configuración que retorna la mejor performance.\n",
    "\n",
    "En caso de tener que combinar varios procesos de extracción y selección de atributos junto con un modelo de aprendizaje, se recomienda utilizar la clase *Pipeline* del paquete *pipeline* de *sklearn*.\n",
    "\n",
    "Tener en cuenta que si la grilla es muy grande, el proceso puede requerir mucho tiempo de cómputo y memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sklearn.grid_search as gs\n",
    "\n",
    "params = {}\n",
    "params[\"SVC\"] = { \n",
    "    'C': [0.5,1,1.5],\n",
    "    'kernel': ['linear', 'poly', 'rbf'],\n",
    "}\n",
    "\n",
    "params[\"DT\"] = {\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'splitter' : ['best', 'random'],\n",
    "    'max_features' : ['auto', 'log2', None],\n",
    "    'min_samples_split' : [1,2,3,0.1,0.2],\n",
    "    'min_samples_leaf' : [1,2,3,0.2,0.4],\n",
    "    'min_impurity_split' : [1e-7,1e-8],\n",
    "    'min_weight_fraction_leaf' : [0,0.1,0.2]\n",
    "}\n",
    "params[\"NB\"] = {\n",
    "    \n",
    "}\n",
    "\n",
    "def obtenerScorer(fn):\n",
    "    return lambda estimator, X, y : fn(y, estimator.predict(np.array(X)))\n",
    "\n",
    "def obtenerMejorEstimador(params, scorer):\n",
    "\n",
    "    for nombre, clf in clfs:\n",
    "\n",
    "        print(\"==> \" + nombre)\n",
    "        gridSearch = gs.GridSearchCV(clf, params[nombre], scoring=scorer)\n",
    "        gridSearch.fit(X_train, y_train)\n",
    "        pad = \" \" * len(\"==>  \")\n",
    "        print(pad + str(gridSearch.best_score_))\n",
    "        print(pad + \"Best params: \" + str(gridSearch.best_params_))\n",
    "\n",
    "print(\"Accuracy\")\n",
    "obtenerMejorEstimador(params, obtenerScorer(metrics.accuracy_score))\n",
    "print(\"Precision\")\n",
    "obtenerMejorEstimador(params, obtenerScorer(lambda y, p: metrics.precision_score(y, p, pos_label=' <=50K')))\n",
    "print(\"Recall\")\n",
    "obtenerMejorEstimador(params, obtenerScorer(lambda y, p: metrics.recall_score(y, p, pos_label=' <=50K')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTAS:**\n",
    "- **Cuáles son los valores de los hiperparámetros con los cuales se obtienen los mejores resultados de performance?**\n",
    "- **Con qué modelo se obtienen los mejores resultados de precision y recall?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Escriba las conclusiones generales que haya obtenido de la tarea.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de Imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección trabajaremos con clasificación de imágenes. Cada instancia a clasificar es una imagen con un dígito escrito a mano. El objetivo es detectar el dígito correspondiente a cada imagen. Para eso utilizaremos un dataset de *sklearn.datasets* que contiene imágenes de dígitos escritos a mano etiquetadas. Cada imagen se representa como un vector de pixeles.\n",
    "\n",
    "Utilizar la función *load_digits* para importar los datos de dígitos escritos a mano. Inspeccionar su contenido (data, target, images y target_names), renderizar el dígito de la primera instancia del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.datasets as datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particionar los datos en dos conjuntos dijuntos de entrenamiento y testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xDigitsTrain,xDigitsTest,yDigitsTrain,yDigitsTest = sklearn.cross_validation.train_test_split(digits.data,digits.target,\n",
    "                                                                                              test_size =0.5)\n",
    "len(digits.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraer atributos de las imágenes para ser utilizados en el modelo de clasificación. Para esto, investigar las clases de Principal Component Analysis (PCA) del paquete sklearn.decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.decomposition\n",
    "\n",
    "pca = sklearn.decomposition.PCA(n_components=16)\n",
    "xDigitsTrain = pca.fit_transform(xDigitsTrain,yDigitsTrain)\n",
    "xDigitsTest = pca.transform(xDigitsTest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Explique el método de extracción de atributos y justifique su elección.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elija dos algoritmos de aprendizaje y entrene e intente obtener los mejores modelos de clasificación posibles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm as svm\n",
    "from sklearn import neural_network\n",
    "\n",
    "\n",
    "svc = svm.SVC(gamma=0.001)\n",
    "svc.fit(xDigitsTrain, yDigitsTrain)\n",
    "predictSvc = svc.predict(xDigitsTest)\n",
    "\n",
    "nn = sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(20,20), max_iter=80000,alpha=0.001)\n",
    "nn.fit(xDigitsTrain,yDigitsTrain)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprima los mejores resultados de precision, recall y accuracy para los algoritmos seleccionados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def imprimir_performance(X, y, clf):\n",
    "    # predicciones = np.array([clf.predict(np.array(x).reshape(1,-1)) for x in X.values])\n",
    "    predicciones = clf.predict(X)\n",
    "        \n",
    "    print(\"Accuracy: \" + str(metrics.accuracy_score(y, predicciones)))\n",
    "    \n",
    "\n",
    "    for l in range(10):\n",
    "        print(\"Label \" + str(l))\n",
    "        print(\"   Precision: \" + str(metrics.precision_score(y, predicciones, average = 'micro', labels=[l])))\n",
    "        print(\"   Recall: \" + str(metrics.recall_score(y, predicciones, average = 'micro', labels=[l])))\n",
    "        print(\"   Medida-f: \" + str(metrics.f1_score(y, predicciones, average = 'micro', labels=[l])))\n",
    "        \n",
    "    print(\"Confussion matrix:\\n\" + str(metrics.confusion_matrix(y, predicciones, )))\n",
    "    \n",
    "    \n",
    "imprimir_performance(xDigitsTest,yDigitsTest,svc)\n",
    "imprimir_performance(xDigitsTest,yDigitsTest,nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Analice los resultados obtenidos.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
