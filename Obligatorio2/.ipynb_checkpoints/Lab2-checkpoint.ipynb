{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el entorno está correctamente instalado, las líneas de código anteriores deben importar los paquetes sin ningún error.\n",
    "\n",
    "Nota: para el resto de las preguntas y soluciones de código, puede ingresar más celdas si lo considera necesario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y estudio de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargue los datos desde el archivo *adult_data.csv*. Para esto puede utilizar la librería *pandas* con su función *read_csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('adult_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprima los nombres de las columnas (atributos), e investigue la documentación para entender que significa cada uno de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'age', u'workclass', u'fnlwgt', u'education', u'education-num',\n",
       "       u'marital-status', u'occupation', u'relationship', u'race', u'sex',\n",
       "       u'capital-gain', u'capital-loss', u'hours-per-week', u'native-country',\n",
       "       u'income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: A continuación realice algunas conjeturas de cuáles pueden llegar a ser los atributos de mayor utilidad para predecir el nivel de ingresos (income) de una persona.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'capital' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d2ea972bdd46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcapital\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mgain\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcapital\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0meducation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moccupation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'capital' is not defined"
     ]
    }
   ],
   "source": [
    "capital-gain\n",
    "capital-loss\n",
    "education\n",
    "occupation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar la columna **income** en un array **y** que será utilizada como atributo clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = df.income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar la columna **fnlwgt** ya que no aporta a la solución del problema. También eliminar la columna **education-num** ya que duplica la información de la columna 'education'. Por último, eliminar la columna **income** ya que es la columna que contiene la clase que se pretende predecir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del df['fnlwgt']\n",
    "del df['education-num']\n",
    "del df['income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los atributos cuyos valores son categorías ('workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'), deben de transformarse a valores numéricos para poder ser utilizados como entradas en los modelos de scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Por qué no es apropiado transformar un atributo de categoría en simples índices numéricos?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA: Porque se generaría una relación de órden y magnitud que el algoritmo de aprendizaje puede tomar y no es real...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice las clases *LabelEncoder* y *OneHotEncoder* del paquete *preprocessing* de *sklearn* para transformar los atributos de categorías en atributos numéricos. Guarde los datos de entrada en una matriz **X**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "\n",
    "aTransformar = ['workclass', 'education', 'marital-status', 'sex','occupation', 'native-country', 'relationship', 'race']\n",
    "\n",
    "le = sklearn.preprocessing.LabelEncoder()\n",
    "\n",
    "for t in aTransformar:\n",
    "    le.fit(df[t])\n",
    "    df[t] = le.transform(df[t])\n",
    "    \n",
    "features = [df.columns.get_loc(f) for f in aTransformar]\n",
    "\n",
    "ohe = sklearn.preprocessing.OneHotEncoder(categorical_features=features, sparse=False)\n",
    "df = pd.DataFrame(data=ohe.fit_transform(df))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>14084.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4971</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4972</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8614.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    ...   93   94   95   \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "2     0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "3     0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  ...   0.0  0.0  0.0   \n",
       "4     0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "5     0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "6     0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "7     0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "8     0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "9     0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "10    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "11    0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "12    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "13    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "14    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "15    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "16    0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "17    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "18    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  ...   0.0  0.0  0.0   \n",
       "19    0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "20    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "21    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "22    0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "23    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  ...   0.0  0.0  0.0   \n",
       "24    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "25    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "26    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "27    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "28    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "29    0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...  ...   \n",
       "4970  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4971  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4972  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4973  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  ...   0.0  0.0  0.0   \n",
       "4974  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4975  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4976  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4977  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4978  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4979  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4980  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4981  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4982  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4983  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4984  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4985  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4986  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4987  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4988  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4989  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4990  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4991  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4992  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4993  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4994  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4995  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4996  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4997  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4998  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "4999  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0  0.0   \n",
       "\n",
       "      96   97   98    99       100     101   102  \n",
       "0     1.0  0.0  0.0  39.0   2174.0     0.0  40.0  \n",
       "1     1.0  0.0  0.0  50.0      0.0     0.0  13.0  \n",
       "2     1.0  0.0  0.0  38.0      0.0     0.0  40.0  \n",
       "3     1.0  0.0  0.0  53.0      0.0     0.0  40.0  \n",
       "4     0.0  0.0  0.0  28.0      0.0     0.0  40.0  \n",
       "5     1.0  0.0  0.0  37.0      0.0     0.0  40.0  \n",
       "6     0.0  0.0  0.0  49.0      0.0     0.0  16.0  \n",
       "7     1.0  0.0  0.0  52.0      0.0     0.0  45.0  \n",
       "8     1.0  0.0  0.0  31.0  14084.0     0.0  50.0  \n",
       "9     1.0  0.0  0.0  42.0   5178.0     0.0  40.0  \n",
       "10    1.0  0.0  0.0  37.0      0.0     0.0  80.0  \n",
       "11    0.0  0.0  0.0  30.0      0.0     0.0  40.0  \n",
       "12    1.0  0.0  0.0  23.0      0.0     0.0  30.0  \n",
       "13    1.0  0.0  0.0  32.0      0.0     0.0  50.0  \n",
       "14    0.0  0.0  0.0  40.0      0.0     0.0  40.0  \n",
       "15    0.0  0.0  0.0  34.0      0.0     0.0  45.0  \n",
       "16    1.0  0.0  0.0  25.0      0.0     0.0  35.0  \n",
       "17    1.0  0.0  0.0  32.0      0.0     0.0  40.0  \n",
       "18    1.0  0.0  0.0  38.0      0.0     0.0  50.0  \n",
       "19    1.0  0.0  0.0  43.0      0.0     0.0  45.0  \n",
       "20    1.0  0.0  0.0  40.0      0.0     0.0  60.0  \n",
       "21    1.0  0.0  0.0  54.0      0.0     0.0  20.0  \n",
       "22    1.0  0.0  0.0  35.0      0.0     0.0  40.0  \n",
       "23    1.0  0.0  0.0  43.0      0.0  2042.0  40.0  \n",
       "24    1.0  0.0  0.0  59.0      0.0     0.0  40.0  \n",
       "25    1.0  0.0  0.0  56.0      0.0     0.0  40.0  \n",
       "26    1.0  0.0  0.0  19.0      0.0     0.0  40.0  \n",
       "27    0.0  0.0  0.0  54.0      0.0     0.0  60.0  \n",
       "28    1.0  0.0  0.0  39.0      0.0     0.0  80.0  \n",
       "29    1.0  0.0  0.0  49.0      0.0     0.0  40.0  \n",
       "...   ...  ...  ...   ...      ...     ...   ...  \n",
       "4970  1.0  0.0  0.0  51.0      0.0     0.0  40.0  \n",
       "4971  1.0  0.0  0.0  46.0      0.0     0.0  40.0  \n",
       "4972  0.0  0.0  0.0  30.0      0.0  1977.0  40.0  \n",
       "4973  0.0  0.0  0.0  37.0      0.0     0.0  35.0  \n",
       "4974  1.0  0.0  0.0  56.0      0.0     0.0  45.0  \n",
       "4975  1.0  0.0  0.0  29.0      0.0     0.0  45.0  \n",
       "4976  1.0  0.0  0.0  46.0      0.0     0.0  50.0  \n",
       "4977  1.0  0.0  0.0  55.0      0.0     0.0  40.0  \n",
       "4978  1.0  0.0  0.0  45.0   8614.0     0.0  48.0  \n",
       "4979  0.0  0.0  0.0  34.0      0.0     0.0  40.0  \n",
       "4980  1.0  0.0  0.0  45.0      0.0     0.0  40.0  \n",
       "4981  1.0  0.0  0.0  41.0      0.0     0.0  40.0  \n",
       "4982  1.0  0.0  0.0  22.0      0.0     0.0  20.0  \n",
       "4983  1.0  0.0  0.0  34.0      0.0     0.0  50.0  \n",
       "4984  1.0  0.0  0.0  27.0      0.0     0.0  40.0  \n",
       "4985  1.0  0.0  0.0  29.0      0.0     0.0  37.0  \n",
       "4986  1.0  0.0  0.0  19.0      0.0     0.0  30.0  \n",
       "4987  1.0  0.0  0.0  47.0      0.0     0.0  40.0  \n",
       "4988  1.0  0.0  0.0  43.0      0.0     0.0  50.0  \n",
       "4989  1.0  0.0  0.0  52.0      0.0     0.0  60.0  \n",
       "4990  1.0  0.0  0.0  33.0      0.0     0.0  60.0  \n",
       "4991  1.0  0.0  0.0  29.0      0.0     0.0  40.0  \n",
       "4992  1.0  0.0  0.0  23.0      0.0     0.0  40.0  \n",
       "4993  1.0  0.0  0.0  23.0      0.0     0.0  40.0  \n",
       "4994  1.0  0.0  0.0  39.0      0.0     0.0  60.0  \n",
       "4995  0.0  0.0  0.0  43.0      0.0     0.0  40.0  \n",
       "4996  1.0  0.0  0.0  31.0      0.0     0.0  40.0  \n",
       "4997  1.0  0.0  0.0  47.0      0.0     0.0  40.0  \n",
       "4998  1.0  0.0  0.0  26.0      0.0     0.0  60.0  \n",
       "4999  1.0  0.0  0.0  58.0      0.0     0.0  55.0  \n",
       "\n",
       "[5000 rows x 103 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Cuántos y cuáles son los nuevos atributos del dataset?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=103, step=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partición de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder entrenar y testear un algoritmo de aprendizaje, es necesario primero particionar los datos en dos conjuntos disjuntos de entrenamiento y testeo. Separe aleatoriamente un 25% de los datos para testeo, llame a los atributos de entrada como **X_test** y al vector de salida esperado **y_test**. El 75% restante se utilizará para el entrenamiento, nombre a la matriz con los datos de entrada como **X_train** y al vector de salida correspondiente como **y_train**.\n",
    "Para esto puede utilizar la función *train_test_split* del paquete *cross_validation* de *sklearn*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgarate.SOFT\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.cross_validation\n",
    "X_train,X_test,y_train,y_test = sklearn.cross_validation.train_test_split(df,y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine el tamaño de las matrices y vectores generados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3750"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3750"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos particionados los datos en entrenamiento y testeo, podemos comenzar a entrenar los algoritmos.\n",
    "\n",
    "Genere un modelo 'dt' entrenando un algoritmo de árboles de decisión (ver el paquete *tree* de *sklearn*) con el vector de entrada X_train y el vector de salida y_train. Utilice los valores por defecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.tree as tree\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genere un modelo 'nb' entrenando un algoritmo de Naive Bayes (ver el paquete *naive_bayes* de *sklearn*) con el vector de entrada X_train y el vector de salida y_train. Utilice los valores por defecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.naive_bayes as naive_bayes\n",
    "\n",
    "\n",
    "nb = naive_bayes.GaussianNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genere un modelo 'svc' entrenando un algoritmo de Support Vector Machines (ver el paquete *svm* de *sklearn*) con el vector de entrada X_train y el vector de salida y_train. Utilice los valores por defecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.svm as svm\n",
    "\n",
    "svc = svm.SVC()\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de tener los modelos entrenados, podemos medir qué tan bien funcionan los modelos (su capacidad de predicción) utlizando medidas standard como accuracy, precision, recall y medida-f."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: De la definición de cada una de las medidas de perfomance (accuracy, precision, recall y medida-f)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-6281de5ff38d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-6281de5ff38d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    accuracy:\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "accuracy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemente una función 'imprimir_performance' que dado un vector de entrada 'X', un vector de salida 'y', y un clasificador 'clf':\n",
    "- Realice la predicción para el vector de entrada X.\n",
    "- Imprima la medida de accuracy.\n",
    "- Imprima precision, recall y medida f de cada clase.\n",
    "- Imprima la matriz de confusión.\n",
    "\n",
    "Para esto puede utilizar el paquete *metrics* de *sklearn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "\n",
    "def imprimir_performance(X, y, clf):\n",
    "    # predicciones = np.array([clf.predict(np.array(x).reshape(1,-1)) for x in X.values])\n",
    "    predicciones = clf.predict(np.array(X))\n",
    "        \n",
    "    print(\"Accuracy: \" + str(metrics.accuracy_score(y, predicciones)))\n",
    "    \n",
    "    for l in [' <=50K', ' >50K']:\n",
    "        print(\"Label \" + l)\n",
    "        print(\"   Precision: \" + str(metrics.precision_score(y, predicciones, pos_label=l)))\n",
    "        print(\"   Recall: \" + str(metrics.recall_score(y, predicciones, pos_label=l)))\n",
    "        print(\"   Medida-f: \" + str(metrics.f1_score(y, predicciones, pos_label=l)))\n",
    "        \n",
    "    print(\"Confussion matrix:\\n\" + str(metrics.confusion_matrix(y, predicciones)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice la función **imprimir_performance** para imprimir las medidas de performance para el clasificador **dt** basado en árboles de decisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.808\n",
      "Label  <=50K\n",
      "   Precision: 0.873404255319\n",
      "   Recall: 0.871549893843\n",
      "   Medida-f: 0.872476089267\n",
      "Label  >50K\n",
      "   Precision: 0.609677419355\n",
      "   Recall: 0.613636363636\n",
      "   Medida-f: 0.611650485437\n",
      "Confussion matrix:\n",
      "[[821 121]\n",
      " [119 189]]\n"
     ]
    }
   ],
   "source": [
    "imprimir_performance(X_test, y_test, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice la función **imprimir_performance** para imprimir las medidas de performance para el clasificador **nb** basado en Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7912\n",
      "Label  <=50K\n",
      "   Precision: 0.927227101631\n",
      "   Recall: 0.784501061571\n",
      "   Medida-f: 0.849913743531\n",
      "Label  >50K\n",
      "   Precision: 0.551876379691\n",
      "   Recall: 0.811688311688\n",
      "   Medida-f: 0.65703022339\n",
      "Confussion matrix:\n",
      "[[739 203]\n",
      " [ 58 250]]\n"
     ]
    }
   ],
   "source": [
    "imprimir_performance(X_test, y_test, nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice la función **imprimir_performance** para imprimir las medidas de performance para el clasificador **svc** basado en Support Vector Machines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.832\n",
      "Label  <=50K\n",
      "   Precision: 0.825044404973\n",
      "   Recall: 0.986199575372\n",
      "   Medida-f: 0.898452611219\n",
      "Label  >50K\n",
      "   Precision: 0.895161290323\n",
      "   Recall: 0.36038961039\n",
      "   Medida-f: 0.513888888889\n",
      "Confussion matrix:\n",
      "[[929  13]\n",
      " [197 111]]\n"
     ]
    }
   ],
   "source": [
    "imprimir_performance(X_test, y_test, svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Realice un breve análisis de los resultados obtenidos.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrene y mida la perfomance de los calsifificadores anteriores, pero ahora utilizando el algoritmo de validación cruzada (cross validation) tomando 5 particiones. Imprima el promedio de accuracy obtenido para cada modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy DT: 0.7952\n",
      "Accuracy NB: 0.785066666667\n",
      "Accuracy SVC: 0.825866666667\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection as ms\n",
    "\n",
    "cross = ms.KFold(n_splits=5)\n",
    "\n",
    "clfs = [(\"DT\", tree.DecisionTreeClassifier()), (\"NB\", naive_bayes.GaussianNB()), (\"SVC\",  svm.SVC())]\n",
    "\n",
    "performances = {}\n",
    "\n",
    "for nombre, clf in clfs:\n",
    "    \n",
    "    sumAcc = 0\n",
    "    \n",
    "    for train, test in cross.split(X_train, y_train):\n",
    "           \n",
    "        clf.fit(X_train.values[train],y_train.values[train])\n",
    "        predicciones = clf.predict(np.array(X_train.values[test]))\n",
    "        sumAcc += metrics.accuracy_score(y_train.values[test], predicciones)\n",
    "    \n",
    "    performances[nombre] = sumAcc/5\n",
    "    \n",
    "    print(\"Accuracy \" + nombre + \": \" + str(sumAcc/5))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Describa brevemente cuáles son las ventajas de utilizar validación cruzada en vez de realizar una único esquema de partición como se hizo al principio.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejorando los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen varias técnicas que pueden ser utilizadas para mejorar los resultados de nuestros modelos. A continuación utilizaremos técnias de **selección de atributos** y de **ajuste de hiperparámetros**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestros entrenamientos hemos utilizado todos los atributos disponibles para entrenar nuestros modelos. Pero no siempre esto lleva a los mejores resultados, de hecho muchas veces, trabajar con un conjunto reducido de atributos devuelve mejores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Investigue de qué se trata la técnica de selección de atributos (feature selection) y argumente brevemente por qué puede mejorar la performance de un algoritmo de aprendizaje automático.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando el paquete *feature_selection* de *sklearn*, seleccione e imprima la lista de los 20 mejores atributos según la medida estadística chi^2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    0,   40],\n",
       "       [   0,    0,    0, ...,    0, 1876,   50],\n",
       "       [   0,    0,    0, ...,    0,    0,   40],\n",
       "       ..., \n",
       "       [   0,    0,    0, ...,    0,    0,   40],\n",
       "       [   0,    1,    0, ...,    0,    0,   70],\n",
       "       [   0,    0,    0, ...,    0,    0,   43]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.feature_selection as fs\n",
    "\n",
    "selector = fs.SelectKBest(fs.chi2,k=20)\n",
    "selector.fit_transform(X_train, y_train).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intente obtener la lista de los mejores N atributos, donde N sea la cantidad mínima posible de atributos que mantenga o mejore las medidas de performance obtenidas con validación cruzada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False]\n",
      "NB\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True False False]\n",
      "SVC\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True  True False]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAFkCAYAAAB1rtL+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlEiIiIhI0pRIiIiISNL+Pw1OOJ7tP2dEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd0ab710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def realizarCV(clf, X, y):\n",
    "    \n",
    "    cross = ms.KFold(n_splits=5)\n",
    "    sumAcc = 0\n",
    "    \n",
    "    for train, test in cross.split(X, y):\n",
    "        \n",
    "        clf.fit(X[train],y.values[train])\n",
    "        predicciones = clf.predict(np.array(X[test]))\n",
    "        sumAcc += metrics.accuracy_score(y.values[test], predicciones)\n",
    "    \n",
    "    return sumAcc / 5\n",
    "\n",
    "plt.clf()\n",
    "selectores = {}\n",
    "\n",
    "for nombre, clf in clfs:\n",
    "\n",
    "    performanceTarget = realizarCV(clf, X_train.values, y_train)\n",
    "    nuevasPerformances = []\n",
    "    mejoresAtributos = []\n",
    "    \n",
    "    for n in xrange(1,20):\n",
    "        kSelector = fs.SelectKBest(fs.chi2,k=n)\n",
    "        X_filtered = kSelector.fit_transform(X_train, y_train).astype(np.int32)\n",
    "        res = realizarCV(clf, X_filtered, y_train)\n",
    "        \n",
    "        if len(mejoresAtributos) == 0 and res > performances[nombre]:\n",
    "            mejoresAtributos = kSelector.get_support()\n",
    "            selectores[nombre] = kSelector\n",
    "\n",
    "        nuevasPerformances.append(res)\n",
    "    \n",
    "    print(nombre)\n",
    "    print(mejoresAtributos)\n",
    "    plt.plot(nuevasPerformances, label=nombre)\n",
    "    \n",
    "    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el conjunto de atributos obtenido, entrene los clasificadores nuevamente y verifique que las medidas de precision, recall mejoran en general:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8024\n",
      "Label  <=50K\n",
      "   Precision: 0.792262405383\n",
      "   Recall: 1.0\n",
      "   Medida-f: 0.884091975598\n",
      "Label  >50K\n",
      "   Precision: 1.0\n",
      "   Recall: 0.198051948052\n",
      "   Medida-f: 0.330623306233\n",
      "Confussion matrix:\n",
      "[[942   0]\n",
      " [247  61]]\n",
      "Accuracy: 0.7896\n",
      "Label  <=50K\n",
      "   Precision: 0.788936170213\n",
      "   Recall: 0.984076433121\n",
      "   Medida-f: 0.875767595654\n",
      "Label  >50K\n",
      "   Precision: 0.8\n",
      "   Recall: 0.194805194805\n",
      "   Medida-f: 0.313315926893\n",
      "Confussion matrix:\n",
      "[[927  15]\n",
      " [248  60]]\n",
      "Accuracy: 0.8264\n",
      "Label  <=50K\n",
      "   Precision: 0.812769628991\n",
      "   Recall: 1.0\n",
      "   Medida-f: 0.896715849595\n",
      "Label  >50K\n",
      "   Precision: 1.0\n",
      "   Recall: 0.295454545455\n",
      "   Medida-f: 0.456140350877\n",
      "Confussion matrix:\n",
      "[[942   0]\n",
      " [217  91]]\n"
     ]
    }
   ],
   "source": [
    "for nombre, clf in clfs:\n",
    "    X_selected = selectores[nombre].transform(X_train)\n",
    "    X_test_selected = selectores[nombre].transform(X_test)\n",
    "    clf.fit(X_selected,y_train)\n",
    "    imprimir_performance(X_test_selected, y_test,clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo general, cada algoritmo y modelo de aprendizaje automático posee parámetros configurables. Estos parámetros se los suele denominar 'hiperparámetros' del algoritmo, ya que son parámetros que el algoritmo no ajusta automáticamente, sino que son ajustados por el \"usuario\".\n",
    "\n",
    "La correcta selección de estos hiperparámetros por lo general tiene una gran incidencia en la performance de los algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Para los modelos generados anteriormente (Árbol de decisión, Naive Bayes y Support Vector Machines), investigue en la documentación de scikit-learn cuáles son sus hiperparámetros y qué valores toman. A continuación liste y de una breve descripción de cada uno:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebe diferentes configuraciones de hiperparámetros para los modelos anteriores de modo de mejorar los resultados de performance obtenidos mediante la función *imprimir_performance*.\n",
    "\n",
    "Para esto puede realizarlo manualmente o buscar una estrategia más avanzada utilizando la clase *GridSearchCV* del paquete *grid_search* de *sklearn*. Esta clase permite definir una grilla de parámetros y posibles valores para luego entrenar el modelo con todas sus posibles combinaciones y devolver la configuración que retorna la mejor performance.\n",
    "\n",
    "En caso de tener que combinar varios procesos de extracción y selección de atributos junto con un modelo de aprendizaje, se recomienda utilizar la clase *Pipeline* del paquete *pipeline* de *sklearn*.\n",
    "\n",
    "Tener en cuenta que si la grilla es muy grande, el proceso puede requerir mucho tiempo de cómputo y memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgarate.SOFT\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best'),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'splitter': ['best', 'random'], 'criterion': ['gini', 'entropy']},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n",
      "NB\n",
      "GridSearchCV(cv=None, error_score='raise', estimator=GaussianNB(priors=None),\n",
      "       fit_params={}, iid=True, n_jobs=1, param_grid={},\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n",
      "SVC\n"
     ]
    }
   ],
   "source": [
    "import sklearn.grid_search as gs\n",
    "\n",
    "params = {}\n",
    "params[\"SVC\"] = { \n",
    "    'C': [0.5,1,1.5],\n",
    "    'kernel': ['linear', 'poly', 'rbf'],\n",
    "}\n",
    "\n",
    "params[\"DT\"] = {\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'splitter' : ['best', 'random']\n",
    "}\n",
    "params[\"NB\"] = {\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "for nombre, clf in clfs:\n",
    "    print(nombre)\n",
    "    gridSearch = gs.GridSearchCV(clf, params[nombre])\n",
    "    a = gridSearch.fit(X_train, y_train)\n",
    "    print(gridSearch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTAS:**\n",
    "- **Cuáles son los valores de los hiperparámetros con los cuales se obtienen los mejores resultados de performance?**\n",
    "- **Con qué modelo se obtienen los mejores resultados de precision y recall?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Escriba las conclusiones generales que haya obtenido de la tarea.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de Imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección trabajaremos con clasificación de imágenes. Cada instancia a clasificar es una imagen con un dígito escrito a mano. El objetivo es detectar el dígito correspondiente a cada imagen. Para eso utilizaremos un dataset de *sklearn.datasets* que contiene imágenes de dígitos escritos a mano etiquetadas. Cada imagen se representa como un vector de pixeles.\n",
    "\n",
    "Utilizar la función *load_digits* para importar los datos de dígitos escritos a mano. Inspeccionar su contenido (data, target, images y target_names), renderizar el dígito de la primera instancia del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbb54c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVgAAAFdCAYAAABGoXXzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb07e080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn.datasets as datasets\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particionar los datos en dos conjuntos dijuntos de entrenamiento y testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xDigitsTrain,xDigitsTest,yDigitsTrain,yDigitsTest = sklearn.cross_validation.train_test_split(digits.data,digits.target,\n",
    "                                                                                              test_size =0.5)\n",
    "len(digits.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraer atributos de las imágenes para ser utilizados en el modelo de clasificación. Para esto, investigar las clases de Principal Component Analysis (PCA) del paquete sklearn.decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.decomposition\n",
    "\n",
    "pca = sklearn.decomposition.PCA(n_components=16)\n",
    "xDigitsTrain = pca.fit_transform(xDigitsTrain,yDigitsTrain)\n",
    "xDigitsTest = pca.transform(xDigitsTest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Explique el método de extracción de atributos y justifique su elección.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elija dos algoritmos de aprendizaje y entrene e intente obtener los mejores modelos de clasificación posibles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(20, 20), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=80000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm as svm\n",
    "from sklearn import neural_network\n",
    "\n",
    "\n",
    "svc = svm.SVC(gamma=0.001)\n",
    "svc.fit(xDigitsTrain, yDigitsTrain)\n",
    "predictSvc = svc.predict(xDigitsTest)\n",
    "\n",
    "nn = sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(20,20), max_iter=80000,alpha=0.001)\n",
    "nn.fit(xDigitsTrain,yDigitsTrain)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprima los mejores resultados de precision, recall y accuracy para los algoritmos seleccionados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.991101223582\n",
      "Label 0\n",
      "   Precision: 1.0\n",
      "   Recall: 1.0\n",
      "   Medida-f: 1.0\n",
      "Label 1\n",
      "   Precision: 0.98\n",
      "   Recall: 1.0\n",
      "   Medida-f: 0.989898989899\n",
      "Label 2\n",
      "   Precision: 1.0\n",
      "   Recall: 1.0\n",
      "   Medida-f: 1.0\n",
      "Label 3\n",
      "   Precision: 1.0\n",
      "   Recall: 0.988372093023\n",
      "   Medida-f: 0.994152046784\n",
      "Label 4\n",
      "   Precision: 0.988764044944\n",
      "   Recall: 0.977777777778\n",
      "   Medida-f: 0.983240223464\n",
      "Label 5\n",
      "   Precision: 0.977011494253\n",
      "   Recall: 0.988372093023\n",
      "   Medida-f: 0.982658959538\n",
      "Label 6\n",
      "   Precision: 1.0\n",
      "   Recall: 1.0\n",
      "   Medida-f: 1.0\n",
      "Label 7\n",
      "   Precision: 0.97619047619\n",
      "   Recall: 0.987951807229\n",
      "   Medida-f: 0.982035928144\n",
      "Label 8\n",
      "   Precision: 1.0\n",
      "   Recall: 0.987341772152\n",
      "   Medida-f: 0.993630573248\n",
      "Label 9\n",
      "   Precision: 0.989130434783\n",
      "   Recall: 0.978494623656\n",
      "   Medida-f: 0.983783783784\n",
      "Confussion matrix:\n",
      "[[101   0   0   0   0   0   0   0   0   0]\n",
      " [  0  98   0   0   0   0   0   0   0   0]\n",
      " [  0   0  97   0   0   0   0   0   0   0]\n",
      " [  0   0   0  85   0   1   0   0   0   0]\n",
      " [  0   1   0   0  88   0   0   1   0   0]\n",
      " [  0   0   0   0   1  85   0   0   0   0]\n",
      " [  0   0   0   0   0   0  86   0   0   0]\n",
      " [  0   0   0   0   0   0   0  82   0   1]\n",
      " [  0   1   0   0   0   0   0   0  78   0]\n",
      " [  0   0   0   0   0   1   0   1   0  91]]\n",
      "Accuracy: 0.953281423804\n",
      "Label 0\n",
      "   Precision: 0.980582524272\n",
      "   Recall: 1.0\n",
      "   Medida-f: 0.990196078431\n",
      "Label 1\n",
      "   Precision: 0.927835051546\n",
      "   Recall: 0.918367346939\n",
      "   Medida-f: 0.923076923077\n",
      "Label 2\n",
      "   Precision: 0.979166666667\n",
      "   Recall: 0.969072164948\n",
      "   Medida-f: 0.974093264249\n",
      "Label 3\n",
      "   Precision: 1.0\n",
      "   Recall: 0.953488372093\n",
      "   Medida-f: 0.97619047619\n",
      "Label 4\n",
      "   Precision: 0.931818181818\n",
      "   Recall: 0.911111111111\n",
      "   Medida-f: 0.921348314607\n",
      "Label 5\n",
      "   Precision: 0.931818181818\n",
      "   Recall: 0.953488372093\n",
      "   Medida-f: 0.942528735632\n",
      "Label 6\n",
      "   Precision: 0.943181818182\n",
      "   Recall: 0.96511627907\n",
      "   Medida-f: 0.954022988506\n",
      "Label 7\n",
      "   Precision: 0.953488372093\n",
      "   Recall: 0.987951807229\n",
      "   Medida-f: 0.970414201183\n",
      "Label 8\n",
      "   Precision: 0.892857142857\n",
      "   Recall: 0.949367088608\n",
      "   Medida-f: 0.920245398773\n",
      "Label 9\n",
      "   Precision: 0.988505747126\n",
      "   Recall: 0.924731182796\n",
      "   Medida-f: 0.955555555556\n",
      "Confussion matrix:\n",
      "[[101   0   0   0   0   0   0   0   0   0]\n",
      " [  0  90   1   0   3   0   0   1   3   0]\n",
      " [  0   1  94   0   0   0   1   0   1   0]\n",
      " [  0   1   1  82   0   1   0   1   0   0]\n",
      " [  0   1   0   0  82   0   4   1   1   1]\n",
      " [  0   2   0   0   2  82   0   0   0   0]\n",
      " [  0   1   0   0   0   0  83   0   2   0]\n",
      " [  0   0   0   0   0   1   0  82   0   0]\n",
      " [  0   1   0   0   1   1   0   1  75   0]\n",
      " [  2   0   0   0   0   3   0   0   2  86]]\n"
     ]
    }
   ],
   "source": [
    "def imprimir_performance(X, y, clf):\n",
    "    # predicciones = np.array([clf.predict(np.array(x).reshape(1,-1)) for x in X.values])\n",
    "    predicciones = clf.predict(X)\n",
    "        \n",
    "    print(\"Accuracy: \" + str(metrics.accuracy_score(y, predicciones)))\n",
    "    \n",
    "\n",
    "    for l in range(10):\n",
    "        print(\"Label \" + str(l))\n",
    "        print(\"   Precision: \" + str(metrics.precision_score(y, predicciones, average = 'micro', labels=[l])))\n",
    "        print(\"   Recall: \" + str(metrics.recall_score(y, predicciones, average = 'micro', labels=[l])))\n",
    "        print(\"   Medida-f: \" + str(metrics.f1_score(y, predicciones, average = 'micro', labels=[l])))\n",
    "        \n",
    "    print(\"Confussion matrix:\\n\" + str(metrics.confusion_matrix(y, predicciones, )))\n",
    "    \n",
    "    \n",
    "imprimir_performance(xDigitsTest,yDigitsTest,svc)\n",
    "imprimir_performance(xDigitsTest,yDigitsTest,nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Analice los resultados obtenidos.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
